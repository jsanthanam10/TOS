{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>clause</th>\n",
       "      <th>severity</th>\n",
       "      <th>a</th>\n",
       "      <th>ch</th>\n",
       "      <th>cr</th>\n",
       "      <th>j</th>\n",
       "      <th>law</th>\n",
       "      <th>ltd</th>\n",
       "      <th>ter</th>\n",
       "      <th>use</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spotify</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spotify</td>\n",
       "      <td>•\\tPremium</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spotify</td>\n",
       "      <td>•\\tHelp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spotify</td>\n",
       "      <td>•\\tDownload</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spotify</td>\n",
       "      <td>•</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12312</th>\n",
       "      <td>Vivino</td>\n",
       "      <td>Where Vivino has provided you with a translati...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12313</th>\n",
       "      <td>Vivino</td>\n",
       "      <td>If there is any contradiction between what the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12314</th>\n",
       "      <td>Vivino</td>\n",
       "      <td>Contact</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12315</th>\n",
       "      <td>Vivino</td>\n",
       "      <td>You may contact Vivino at the following addres...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12316</th>\n",
       "      <td>Vivino</td>\n",
       "      <td>sal, DK-2300 Copenhagen, Denmark</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12317 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      document                                             clause  severity  \\\n",
       "0      Spotify                                            Spotify         0   \n",
       "1      Spotify                                         •\\tPremium         0   \n",
       "2      Spotify                                            •\\tHelp         0   \n",
       "3      Spotify                                        •\\tDownload         0   \n",
       "4      Spotify                                                  •         0   \n",
       "...        ...                                                ...       ...   \n",
       "12312   Vivino  Where Vivino has provided you with a translati...         0   \n",
       "12313   Vivino  If there is any contradiction between what the...         0   \n",
       "12314   Vivino                                            Contact         0   \n",
       "12315   Vivino  You may contact Vivino at the following addres...         0   \n",
       "12316   Vivino                   sal, DK-2300 Copenhagen, Denmark         0   \n",
       "\n",
       "       a  ch  cr  j  law  ltd  ter  use  \n",
       "0      0   0   0  0    0    0    0    0  \n",
       "1      0   0   0  0    0    0    0    0  \n",
       "2      0   0   0  0    0    0    0    0  \n",
       "3      0   0   0  0    0    0    0    0  \n",
       "4      0   0   0  0    0    0    0    0  \n",
       "...   ..  ..  .. ..  ...  ...  ...  ...  \n",
       "12312  0   0   0  0    0    0    0    0  \n",
       "12313  0   0   0  0    0    0    0    0  \n",
       "12314  0   0   0  0    0    0    0    0  \n",
       "12315  0   0   0  0    0    0    0    0  \n",
       "12316  0   0   0  0    0    0    0    0  \n",
       "\n",
       "[12317 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../combined.csv')\n",
    "# get rid of unamed column\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = df\n",
    "X = data_cleaned['clause']\n",
    "y_tags = data_cleaned[['a', 'ch', 'cr', 'j', 'law', 'ltd', 'ter', 'use']]\n",
    "y_severity = data_cleaned['severity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9387175324675324"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model to predict severity of the clause\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Splitting the data into training and testing sets for severity\n",
    "X_train_sev, X_test_sev, y_train_sev, y_test_sev = train_test_split(X, y_severity, test_size=0.2, random_state=42)\n",
    "\n",
    "# Text Preprocessing: Reusing the earlier vectorizer\n",
    "X_train_sev_tfidf = vectorizer.transform(X_train_sev)\n",
    "X_test_sev_tfidf = vectorizer.transform(X_test_sev)\n",
    "\n",
    "# Model for Severity: Random Forest Classifier\n",
    "severity_classifier = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Training the model for severity\n",
    "severity_classifier.fit(X_train_sev_tfidf, y_train_sev)\n",
    "\n",
    "# Predicting on the test set for severity\n",
    "y_pred_sev = severity_classifier.predict(X_test_sev_tfidf)\n",
    "\n",
    "# Evaluation for Severity\n",
    "accuracy_sev = accuracy_score(y_test_sev, y_pred_sev)\n",
    "\n",
    "accuracy_sev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "tokenizer_config.json: 100%|██████████| 28.0/28.0 [00:00<00:00, 43.1kB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 598kB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 633kB/s]\n",
      "config.json: 100%|██████████| 570/570 [00:00<00:00, 1.88MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'text': 'your netflix membership may start with a free trial.',\n",
       "  'input_ids': tensor([  101,  2115, 20907,  5779,  2089,  2707,  2007,  1037,  2489,  3979,\n",
       "           1012,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0]),\n",
       "  'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'labels': tensor([0., 0., 0., 0., 0., 0., 0., 0.])},\n",
       " device(type='cpu'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "# Define a dataset class\n",
    "class TOSDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.texts[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Define the maximum length for tokenization\n",
    "MAX_LEN = 128\n",
    "X = df['clause']\n",
    "y_tags = df[['a', 'ch', 'cr', 'j', 'law', 'ltd', 'ter', 'use']]\n",
    "\n",
    "# Splitting the data into training and testing sets for tags\n",
    "X_train_tags, X_test_tags, y_train_tags, y_test_tags = train_test_split(X, y_tags, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = TOSDataset(X_train_tags.to_numpy(), y_train_tags.to_numpy(), tokenizer, MAX_LEN)\n",
    "test_dataset = TOSDataset(X_test_tags.to_numpy(), y_test_tags.to_numpy(), tokenizer, MAX_LEN)\n",
    "\n",
    "# Check if the datasets are prepared correctly\n",
    "train_dataset[0], device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jessicasanthanam/Repos/TOC/main/model.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jessicasanthanam/Repos/TOC/main/model.ipynb#W6sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(logits\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(y_tags\u001b[39m.\u001b[39mcolumns)), batch[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtype_as(logits))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jessicasanthanam/Repos/TOC/main/model.ipynb#W6sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Backward pass\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jessicasanthanam/Repos/TOC/main/model.ipynb#W6sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jessicasanthanam/Repos/TOC/main/model.ipynb#W6sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Update parameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jessicasanthanam/Repos/TOC/main/model.ipynb#W6sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import torch\n",
    "# from torch.optim import AdamW\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from tqdm import tqdm \n",
    "\n",
    "# Assuming the TOSDataset class and the data split are already defined as per your previous code\n",
    "\n",
    "# Load the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(y_tags.columns)  # The number of output labels\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function to handle batches of dictionaries.\n",
    "    \"\"\"\n",
    "    # Stacking the values of each key from a list of dictionaries\n",
    "    batch = {key: default_collate([d[key] for d in batch]) for key in batch[0]}\n",
    "    return batch\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "loss_function = BCEWithLogitsLoss()\n",
    "\n",
    "num_epochs = 1\n",
    "# Training Loop\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        \n",
    "        # Move only the tensors to the device, ignore 'text' or any other non-tensor data\n",
    "        batch = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_function(logits.view(-1, len(y_tags.columns)), batch['labels'].type_as(logits))\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Zero the gradients after updating\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Accumulate the loss\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Print the average loss per epoch\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {avg_train_loss}')\n",
    "\n",
    "# Evaluation Loop\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "    logits = outputs.logits\n",
    "    predictions.append(logits.cpu().numpy())\n",
    "    true_labels.append(batch['labels'].cpu().numpy())\n",
    "\n",
    "# Convert predictions to binary (you may choose a threshold, e.g., 0.5)\n",
    "# Calculate the accuracy or other metrics using sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Concatenate the predictions and true labels\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Apply sigmoid to the logits to get probabilities and then apply the threshold\n",
    "probabilities = torch.sigmoid(torch.from_numpy(predictions)).numpy()\n",
    "threshold = 0.5\n",
    "binary_predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "# Calculate the accuracy for each label\n",
    "label_accuracies = []\n",
    "for i in range(len(y_tags.columns)):\n",
    "    label_accuracy = accuracy_score(true_labels[:, i], binary_predictions[:, i])\n",
    "    label_accuracies.append(label_accuracy)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = accuracy_score(true_labels, binary_predictions)\n",
    "\n",
    "# Calculate the F1 score for each label\n",
    "label_f1_scores = []\n",
    "for i in range(len(y_tags.columns)):\n",
    "    label_f1_score = f1_score(true_labels[:, i], binary_predictions[:, i], average='macro')\n",
    "    label_f1_scores.append(label_f1_score)\n",
    "\n",
    "# Calculate the overall F1 score\n",
    "overall_f1_score = f1_score(true_labels, binary_predictions, average='macro')\n",
    "\n",
    "# Classification report for each label\n",
    "detailed_report = classification_report(true_labels, binary_predictions, target_names=y_tags.columns)\n",
    "\n",
    "print(\"Accuracy for each label: \", label_accuracies)\n",
    "print(\"Overall accuracy: \", overall_accuracy)\n",
    "print(\"F1 Score for each label: \", label_f1_scores)\n",
    "print(\"Overall F1 Score: \", overall_f1_score)\n",
    "print(\"Detailed classification report: \\n\", detailed_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
